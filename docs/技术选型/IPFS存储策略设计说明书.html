<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>IPFS存储策略设计说明书</title>
    <style>
        body {
            max-width: 860px;
            margin: 32px auto;
            padding: 0 16px;
            font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica, Arial, "Noto Sans", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", sans-serif;
            line-height: 1.6;
            color: #1f2937;
        }
        pre { background:#f8fafc; padding:12px; overflow:auto; border-radius:6px; }
        code { background:#f1f5f9; padding:2px 4px; border-radius:4px; }
        h1,h2,h3,h4,h5,h6 { line-height:1.25; }
        a { color:#2563eb; text-decoration:none; }
        a:hover { text-decoration:underline; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #e5e7eb; padding: 8px; }
        blockquote { margin: 0; padding-left: 1em; border-left: 4px solid #e5e7eb; color:#6b7280; }
    </style>
</head>
<body>
<h1>IPFS存储策略设计说明书</h1>
<p>> 用词规范：请参阅《[项目术语表](../项目术语表.md)》以确保术语统一。</p>
<br/>
<h2>1. 概述</h2>
<br/>
<h3>1.1 设计目标</h3>
<p>本系统采用**IPFS（InterPlanetary File System）**作为主要存储方案，完全替代传统的"链下存储"概念。通过IPFS的去中心化特性，实现数据的高可用性、不可篡改性和成本效益的完美平衡。</p>
<br/>
<h3>1.2 为什么选择IPFS替代链下存储？</h3>
<br/>
<p>#### 1.2.3 与NFT类型驱动的集成优势与边界</p>
<p>- **投票项目属性接口**：投票项目管理作为NFT管理的属性接口，其配置均为NFT类型的全局参数；完整配置/版本明细写入IPFS，链上仅保存CID/哈希</p>
<p>- **NFT元数据存储**：每个NFT类型的元数据与相关配置存储在IPFS上</p>
<p>- **状态变量同步**：NFT状态变量的变更以CID/哈希形式同步至链上进行完整性验证</p>
<p>- **数据边界清晰**：详细投票数据（承诺/揭示、参与者、计算过程与证明）位于IPFS；链上仅保留账户-NFT关联与结果摘要</p>
<p>- **去中心化一致性**：IPFS与区块链双重验证确保数据一致性</p>
<br/>
<p>#### 1.2.1 传统链下存储的问题</p>
<p>- **中心化风险**：依赖单一存储服务提供商</p>
<p>- **成本控制**：存储费用难以预测和控制</p>
<p>- **数据主权**：数据控制权不完全在用户手中</p>
<p>- **可用性风险**：服务中断导致数据不可访问</p>
<br/>
<p>#### 1.2.2 IPFS的优势</p>
<p>- **完全去中心化**：数据分布在全球节点网络中</p>
<p>- **零成本存储**：无需支付存储费用</p>
<p>- **数据主权**：用户完全控制自己的数据</p>
<p>- **高可用性**：多节点冗余，避免单点故障</p>
<p>- **内容寻址**：通过哈希确保数据完整性</p>
<br/>
<h2>2. IPFS存储架构设计</h2>
<br/>
<h3>2.1 整体架构</h3>
<br/>
<pre><code>
┌─────────────────────────────────────────────────────────────┐
│                    客户端应用层                              │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                   IPFS存储适配层                             │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │ 本地IPFS节点│ │ 公共网关    │ │ 固定服务    │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                   IPFS网络层                                 │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │ 内容寻址    │ │ 分布式哈希表│ │ 块交换协议  │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                   区块链验证层                               │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │ 数据哈希    │ │ 存储证明    │ │ 访问控制    │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
└─────────────────────────────────────────────────────────────┘
</code></pre>
<br/>
<h3>2.2 存储层次结构</h3>
<br/>
<p>#### 2.2.1 主要存储层（IPFS）</p>
<pre><code>
pub enum IPFSStorageLayer {
    LocalNode,      // 本地IPFS节点
    PublicGateway,  // 公共网关
    PinningService, // 固定服务
    Distributed,    // 分布式网络
}
</code></pre>
<br/>
<p>#### 2.2.2 验证层（区块链）</p>
<pre><code>
pub enum BlockchainVerification {
    DataHash,       // 数据哈希存储
    StorageProof,   // 存储证明
    AccessControl,  // 访问控制
}
</code></pre>
<br/>
<h2>3. 核心数据结构</h2>
<br/>
<h3>3.1 IPFS配置结构</h3>
<pre><code>
#[derive(Debug, Clone)]
pub struct IPFSConfig {
    pub gateway_urls: Vec&lt;String&gt;,           // 公共网关列表
    pub local_node: Option&lt;LocalIPFSNode&gt;,   // 本地节点配置
    pub pinning_services: Vec&lt;PinningService&gt;, // 固定服务配置
    pub redundancy_factor: u32,              // 冗余因子
    pub data_retention_days: u32,            // 数据保留天数
    pub compression_enabled: bool,           // 是否启用压缩
    pub encryption_enabled: bool,            // 是否启用加密
}

#[derive(Debug, Clone)]
pub struct LocalIPFSNode {
    pub api_url: String,                     // API端点
    pub data_path: String,                   // 数据存储路径
    pub max_storage_gb: u64,                 // 最大存储容量
    pub auto_gc: bool,                       // 自动垃圾回收
    pub gc_interval_hours: u32,              // 垃圾回收间隔
}

#[derive(Debug, Clone)]
pub struct PinningService {
    pub name: String,                        // 服务名称
    pub api_key: String,                     // API密钥
    pub endpoint: String,                    // 服务端点
    pub cost_per_gb: f64,                   // 每GB成本
    pub max_file_size_gb: u64,              // 最大文件大小
    pub retention_policy: RetentionPolicy,  // 保留策略
}

#[derive(Debug, Clone)]
pub enum RetentionPolicy {
    Permanent,                               // 永久保留
    TimeBased(Duration),                     // 基于时间
    UsageBased(u32),                        // 基于使用量
}
</code></pre>
<br/>
<h3>3.2 存储结果结构</h3>
<pre><code>
#[derive(Debug, Clone)]
pub struct IPFSStorageResult {
    pub content_id: String,                  // IPFS CID
    pub storage_locations: Vec&lt;StorageLocation&gt;, // 存储位置
    pub metadata: StorageMetadata,           // 存储元数据
    pub verification: StorageVerification,   // 验证信息
}

#[derive(Debug, Clone)]
pub struct StorageLocation {
    pub provider: StorageProvider,           // 存储提供商
    pub url: String,                         // 访问URL
    pub status: StorageStatus,               // 存储状态
    pub last_verified: u64,                  // 最后验证时间
}

#[derive(Debug, Clone)]
pub enum StorageProvider {
    LocalIPFS,                               // 本地IPFS节点
    PublicGateway(String),                   // 公共网关
    PinningService(String),                  // 固定服务
    Distributed,                             // 分布式网络
}

#[derive(Debug, Clone)]
pub enum StorageStatus {
    Available,                               // 可用
    Pending,                                 // 待处理
    Failed,                                  // 失败
    Unavailable,                             // 不可用
}
</code></pre>
<br/>
<h2>4. 存储策略实现</h2>
<br/>
<h3>4.1 主要存储策略</h3>
<pre><code>
impl StorageStrategy {
    pub async fn store_to_ipfs_with_redundancy(
        &amp;self,
        data: &amp;[u8],
        data_type: DataType
    ) -&gt; Result&lt;IPFSStorageResult, Box&lt;dyn std::error::Error&gt;&gt; {
        let mut storage_locations = Vec::new();
        
        // 1. 数据预处理
        let processed_data = self.preprocess_data(data, data_type).await?;
        
        // 2. 存储到本地IPFS节点
        if let Some(local_node) = &amp;self.ipfs_config.local_node {
            let local_result = self.store_to_local_ipfs(&amp;processed_data, local_node).await?;
            storage_locations.push(local_result);
        }
        
        // 3. 存储到公共网关
        for gateway in &amp;self.ipfs_config.gateway_urls {
            let gateway_result = self.store_to_public_gateway(&amp;processed_data, gateway).await?;
            storage_locations.push(gateway_result);
        }
        
        // 4. 使用固定服务
        for service in &amp;self.ipfs_config.pinning_services {
            let service_result = self.pin_to_service(&amp;processed_data, service).await?;
            storage_locations.push(service_result);
        }
        
        // 5. 分布式存储
        let distributed_result = self.store_to_distributed_network(&amp;processed_data).await?;
        storage_locations.push(distributed_result);
        
        // 6. 生成存储结果
        let result = IPFSStorageResult {
            content_id: processed_data.cid.clone(),
            storage_locations,
            metadata: processed_data.metadata,
            verification: self.generate_verification(&amp;processed_data).await?,
        };
        
        Ok(result)
    }
}
</code></pre>
<br/>
<h3>4.2 数据预处理</h3>
<pre><code>
impl StorageStrategy {
    async fn preprocess_data(
        &amp;self,
        data: &amp;[u8],
        data_type: DataType
    ) -&gt; Result&lt;ProcessedData, Box&lt;dyn std::error::Error&gt;&gt; {
        let mut processed_data = data.to_vec();
        
        // 1. 数据压缩
        if self.ipfs_config.compression_enabled {
            processed_data = self.compress_data(&amp;processed_data).await?;
        }
        
        // 2. 数据加密（可选）
        if self.ipfs_config.encryption_enabled {
            processed_data = self.encrypt_data(&amp;processed_data).await?;
        }
        
        // 3. 生成IPFS CID
        let cid = self.generate_ipfs_cid(&amp;processed_data).await?;
        
        // 4. 创建元数据
        let metadata = StorageMetadata {
            original_size: data.len(),
            compressed_size: processed_data.len(),
            compression_ratio: data.len() as f64 / processed_data.len() as f64,
            encryption_enabled: self.ipfs_config.encryption_enabled,
            data_type,
            created_at: self.get_current_timestamp(),
        };
        
        Ok(ProcessedData {
            data: processed_data,
            cid,
            metadata,
        })
    }
}
</code></pre>
<br/>
<h3>4.3 本地IPFS节点存储</h3>
<pre><code>
impl StorageStrategy {
    async fn store_to_local_ipfs(
        &amp;self,
        data: &amp;ProcessedData,
        local_node: &amp;LocalIPFSNode
    ) -&gt; Result&lt;StorageLocation, Box&lt;dyn std::error::Error&gt;&gt; {
        // 1. 检查存储容量
        let available_space = self.check_available_space(local_node).await?;
        if available_space &lt; data.data.len() as u64 {
            return Err("Insufficient storage space".into());
        }
        
        // 2. 存储到IPFS
        let cid = self.ipfs_client.add_data(&amp;data.data).await?;
        
        // 3. 固定数据（防止垃圾回收）
        self.ipfs_client.pin_add(&amp;cid).await?;
        
        // 4. 验证存储
        let stored_data = self.ipfs_client.cat(&amp;cid).await?;
        if stored_data != data.data {
            return Err("Data integrity check failed".into());
        }
        
        Ok(StorageLocation {
            provider: StorageProvider::LocalIPFS,
            url: format!("ipfs://{}", cid),
            status: StorageStatus::Available,
            last_verified: self.get_current_timestamp(),
        })
    }
}
</code></pre>
<br/>
<h3>4.4 公共网关存储</h3>
<pre><code>
impl StorageStrategy {
    async fn store_to_public_gateway(
        &amp;self,
        data: &amp;ProcessedData,
        gateway: &amp;str
    ) -&gt; Result&lt;StorageLocation, Box&lt;dyn std::error::Error&gt;&gt; {
        // 1. 通过网关上传数据
        let response = self.http_client
            .post(&amp;format!("{}/api/v0/add", gateway))
            .multipart(self.create_multipart_form(data))
            .send()
            .await?;
        
        // 2. 解析响应
        let result: IPFSResponse = response.json().await?;
        let cid = result.hash;
        
        // 3. 验证上传
        let verification_url = format!("{}/ipfs/{}", gateway, cid);
        let verification_response = self.http_client.get(&amp;verification_url).send().await?;
        
        if verification_response.status().is_success() {
            Ok(StorageLocation {
                provider: StorageProvider::PublicGateway(gateway.to_string()),
                url: verification_url,
                status: StorageStatus::Available,
                last_verified: self.get_current_timestamp(),
            })
        } else {
            Err("Gateway storage verification failed".into())
        }
    }
}
</code></pre>
<br/>
<h2>5. 数据验证和完整性</h2>
<br/>
<h3>5.1 区块链验证机制</h3>
<pre><code>
pub struct BlockchainVerifier {
    pub contract_client: ContractClient,
    pub verification_contract: String,
}

impl BlockchainVerifier {
    pub async fn store_verification(
        &amp;self,
        cid: &amp;str,
        data_hash: &amp;[u8; 32],
        metadata: &amp;StorageMetadata
    ) -&gt; Result&lt;String, Box&lt;dyn std::error::Error&gt;&gt; {
        // 1. 存储数据哈希到区块链
        let tx_hash = self.contract_client.execute(
            &amp;self.verification_contract,
            "store_data_verification",
            &amp;json!({
                "cid": cid,
                "data_hash": hex::encode(data_hash),
                "metadata": metadata,
                "timestamp": self.get_current_timestamp(),
            })
        ).await?;
        
        Ok(tx_hash)
    }
    
    pub async fn verify_data_integrity(
        &amp;self,
        cid: &amp;str,
        data: &amp;[u8]
    ) -&gt; Result&lt;bool, Box&lt;dyn std::error::Error&gt;&gt; {
        // 1. 从区块链获取存储的哈希
        let stored_hash = self.contract_client.query(
            &amp;self.verification_contract,
            "get_data_hash",
            &amp;json!({ "cid": cid })
        ).await?;
        
        // 2. 计算当前数据的哈希
        let current_hash = self.calculate_hash(data);
        
        // 3. 比较哈希值
        Ok(stored_hash == hex::encode(current_hash))
    }
}
</code></pre>
<br/>
<h3>5.2 数据可用性监控</h3>
<pre><code>
pub struct DataAvailabilityMonitor {
    pub check_interval: Duration,
    pub alert_threshold: u32,
    pub notification_service: NotificationService,
}

impl DataAvailabilityMonitor {
    pub async fn start_monitoring(&amp;self) {
        let mut interval = tokio::time::interval(self.check_interval);
        
        loop {
            interval.tick().await;
            
            // 检查所有存储位置的数据可用性
            let availability_report = self.check_all_storage_locations().await;
            
            // 处理不可用的数据
            self.handle_unavailable_data(&amp;availability_report).await;
            
            // 发送通知
            if availability_report.unavailable_count &gt; self.alert_threshold {
                self.notification_service.send_alert(&amp;availability_report).await;
            }
        }
    }
    
    async fn check_all_storage_locations(&amp;self) -&gt; AvailabilityReport {
        // 实现数据可用性检查逻辑
        todo!()
    }
    
    async fn handle_unavailable_data(&amp;self, report: &amp;AvailabilityReport) {
        for unavailable_location in &amp;report.unavailable_locations {
            // 尝试从其他位置恢复数据
            if let Ok(recovered_data) = self.recover_data(unavailable_location).await {
                // 重新存储到可用位置
                self.restore_data(&amp;recovered_data).await;
            }
        }
    }
}
</code></pre>
<br/>
<h2>6. 性能优化策略</h2>
<br/>
<h3>6.1 缓存策略</h3>
<pre><code>
pub struct IPFSCache {
    pub memory_cache: LruCache&lt;String, CachedData&gt;,
    pub disk_cache: DiskCache,
    pub cache_ttl: Duration,
}

impl IPFSCache {
    pub async fn get_or_fetch(
        &amp;self,
        cid: &amp;str
    ) -&gt; Result&lt;Vec&lt;u8&gt;, Box&lt;dyn std::error::Error&gt;&gt; {
        // 1. 检查内存缓存
        if let Some(cached_data) = self.memory_cache.get(cid) {
            if !cached_data.is_expired() {
                return Ok(cached_data.data.clone());
            }
        }
        
        // 2. 检查磁盘缓存
        if let Some(cached_data) = self.disk_cache.get(cid).await? {
            if !cached_data.is_expired() {
                // 更新内存缓存
                self.memory_cache.put(cid.to_string(), cached_data.clone());
                return Ok(cached_data.data);
            }
        }
        
        // 3. 从IPFS获取数据
        let data = self.fetch_from_ipfs(cid).await?;
        
        // 4. 更新缓存
        let cached_data = CachedData {
            data: data.clone(),
            created_at: self.get_current_timestamp(),
            ttl: self.cache_ttl,
        };
        
        self.memory_cache.put(cid.to_string(), cached_data.clone());
        self.disk_cache.put(cid, &amp;cached_data).await?;
        
        Ok(data)
    }
}
</code></pre>
<br/>
<h3>6.2 并行处理</h3>
<pre><code>
impl StorageStrategy {
    pub async fn store_parallel(
        &amp;self,
        data: &amp;[u8],
        data_type: DataType
    ) -&gt; Result&lt;IPFSStorageResult, Box&lt;dyn std::error::Error&gt;&gt; {
        let processed_data = self.preprocess_data(data, data_type).await?;
        
        // 并行存储到多个位置
        let storage_tasks = vec![
            self.store_to_local_ipfs_task(&amp;processed_data),
            self.store_to_public_gateways_task(&amp;processed_data),
            self.store_to_pinning_services_task(&amp;processed_data),
            self.store_to_distributed_network_task(&amp;processed_data),
        ];
        
        let results = futures::future::join_all(storage_tasks).await;
        
        // 收集成功的结果
        let mut storage_locations = Vec::new();
        for result in results {
            if let Ok(location) = result {
                storage_locations.push(location);
            }
        }
        
        Ok(IPFSStorageResult {
            content_id: processed_data.cid,
            storage_locations,
            metadata: processed_data.metadata,
            verification: self.generate_verification(&amp;processed_data).await?,
        })
    }
}
</code></pre>
<br/>
<h2>7. 配置和部署</h2>
<br/>
<h3>7.1 配置文件示例</h3>
<pre><code>
# config/ipfs-storage.yaml
ipfs_storage:
  # 本地节点配置
  local_node:
    enabled: true
    api_url: "http://localhost:5001"
    data_path: "/var/lib/ipfs"
    max_storage_gb: 100
    auto_gc: true
    gc_interval_hours: 24
  
  # 公共网关配置
  public_gateways:
    - "https://ipfs.io"
    - "https://gateway.pinata.cloud"
    - "https://cloudflare-ipfs.com"
    - "https://dweb.link"
  
  # 固定服务配置
  pinning_services:
    - name: "Pinata"
      api_key: "${PINATA_API_KEY}"
      endpoint: "https://api.pinata.cloud"
      cost_per_gb: 0.0
      max_file_size_gb: 1
      retention_policy: "permanent"
    
    - name: "Infura"
      api_key: "${INFURA_API_KEY}"
      endpoint: "https://ipfs.infura.io"
      cost_per_gb: 0.0
      max_file_size_gb: 5
      retention_policy: "permanent"
  
  # 存储策略配置
  redundancy_factor: 3
  data_retention_days: 365
  compression_enabled: true
  encryption_enabled: false
</code></pre>
<br/>
<h3>7.2 Docker部署配置</h3>
<pre><code>
# Dockerfile.ipfs
FROM ipfs/kubo:latest

# 安装必要的工具
RUN apk add --no-cache curl jq

# 配置IPFS
COPY ipfs-config.json /root/.ipfs/config

# 暴露API端口
EXPOSE 5001

# 启动IPFS守护进程
CMD ["ipfs", "daemon", "--migrate=true"]
</code></pre>
<br/>
<pre><code>
# docker-compose.ipfs.yml
version: '3.8'
services:
  ipfs-node:
    build:
      context: .
      dockerfile: Dockerfile.ipfs
    ports:
      - "5001:5001"
      - "4001:4001"
      - "8080:8080"
    volumes:
      - ipfs-data:/data/ipfs
      - ipfs-staging:/export
    environment:
      - IPFS_PROFILE=server
    restart: unless-stopped

volumes:
  ipfs-data:
  ipfs-staging:
</code></pre>
<br/>
<h2>8. 监控和维护</h2>
<br/>
<h3>8.1 性能指标</h3>
<pre><code>
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IPFSMetrics {
    pub storage_operations: StorageMetrics,
    pub retrieval_operations: RetrievalMetrics,
    pub network_metrics: NetworkMetrics,
    pub cache_metrics: CacheMetrics,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageMetrics {
    pub total_stored_bytes: u64,
    pub total_files: u64,
    pub average_storage_time_ms: f64,
    pub storage_success_rate: f64,
    pub redundancy_level: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RetrievalMetrics {
    pub total_retrieved_bytes: u64,
    pub total_requests: u64,
    pub average_retrieval_time_ms: f64,
    pub cache_hit_rate: f64,
    pub availability_rate: f64,
}
</code></pre>
<br/>
<h3>8.2 健康检查</h3>
<pre><code>
pub struct IPFSHealthChecker {
    pub check_interval: Duration,
    pub health_checks: Vec&lt;Box&lt;dyn HealthCheck&gt;&gt;,
}

impl IPFSHealthChecker {
    pub async fn perform_health_check(&amp;self) -&gt; HealthReport {
        let mut report = HealthReport::new();
        
        for health_check in &amp;self.health_checks {
            match health_check.check().await {
                Ok(status) =&gt; report.add_check_result(status),
                Err(error) =&gt; report.add_error(error.to_string()),
            }
        }
        
        report
    }
}

pub trait HealthCheck {
    async fn check(&amp;self) -&gt; Result&lt;CheckStatus, Box&lt;dyn std::error::Error&gt;&gt;;
}

pub struct LocalNodeHealthCheck;
pub struct GatewayHealthCheck;
pub struct PinningServiceHealthCheck;

impl HealthCheck for LocalNodeHealthCheck {
    async fn check(&amp;self) -&gt; Result&lt;CheckStatus, Box&lt;dyn std::error::Error&gt;&gt; {
        // 检查本地IPFS节点状态
        let response = reqwest::get("http://localhost:5001/api/v0/version").await?;
        
        if response.status().is_success() {
            Ok(CheckStatus::Healthy)
        } else {
            Ok(CheckStatus::Unhealthy)
        }
    }
}
</code></pre>
<br/>
<h2>9. 总结</h2>
<br/>
<h3>9.1 技术优势</h3>
<br/>
<p>通过采用IPFS作为主要存储方案，系统实现了以下优势：</p>
<br/>
<p>1. **完全去中心化**：数据分布在全球节点网络中，避免单点故障</p>
<p>2. **零成本存储**：无需支付存储费用，降低运营成本</p>
<p>3. **数据主权**：用户完全控制自己的数据，符合去中心化理念</p>
<p>4. **高可用性**：多节点冗余，确保数据始终可访问</p>
<p>5. **内容寻址**：通过哈希确保数据完整性和不可篡改性</p>
<br/>
<h3>9.2 实施建议</h3>
<br/>
<p>1. **渐进式部署**：先部署本地IPFS节点，再集成公共网关和固定服务</p>
<p>2. **监控和告警**：建立完善的监控体系，及时发现和处理问题</p>
<p>3. **性能优化**：通过缓存、并行处理等技术提升用户体验</p>
<p>4. **数据备份**：建立多重备份机制，确保数据安全</p>
<br/>
<h3>9.3 未来扩展</h3>
<br/>
<p>1. **多链支持**：集成更多区块链平台，提升验证的多样性</p>
<p>2. **智能路由**：根据网络状况自动选择最优的存储路径</p>
<p>3. **存储市场**：与IPFS存储提供商建立合作关系，提供增值服务</p>
<p>4. **生态建设**：参与IPFS社区建设，推动技术发展</p>
<br/>
<p>通过本设计，系统成功实现了从传统"链下存储"向"IPFS去中心化存储"的转变，为用户提供了更加安全、可靠、经济的存储解决方案。</p>
<br/>
<h2>评估标准与结论</h2>
<br/>
<h3>评估标准（统一口径）</h3>
<p>- SoT：以 IPFS 的 CID/版本 为唯一真实源；链上仅保留摘要/索引。</p>
<p>- 可用性：多网关、多Pin服务、本地节点冗余与健康检查。</p>
<p>- 经济性：链上最小化显著降低Gas与状态膨胀。</p>
<p>- 可验证性：Merkle/哈希 + CID 交叉校验链路完备。</p>
<br/>
<h3>结论</h3>
<p>该方案满足可用性、经济性与可验证性需求，建议按冗余与监控配置上线实施。</p>
<br/>
<p>---</p>
<br/>
<p>**文档编制日期**：2025年8月</p>
<p>**文档编制人**：luckeeDAO技术评估团队</p>
<p>**文档审核人**：luckeeDAO管理委员会</p>
</body>
</html>